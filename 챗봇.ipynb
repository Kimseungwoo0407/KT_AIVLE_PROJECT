{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# env 이런식으로 저장해주세요\n",
        "# 드라이브 마운트하셔서 아래 코드 실행하시는데 본인 API KEY로 바꾸시면 됩니\n",
        "\n",
        "env_content = \"\"\"\n",
        "OPENAI_API_KEY=본인 키 입력\n",
        "LANGCHAIN_TRACING_V2=true\n",
        "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
        "LANGCHAIN_API_KEY=본인 키 입력\n",
        "LANGCHAIN_PROJECT=Projects\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/drive/MyDrive/env', 'w') as f:\n",
        "    f.write(env_content)\n"
      ],
      "metadata": {
        "id": "X2ZpcfNylDnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install load_dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6p-eZ1nlhB0",
        "outputId": "94722503-6beb-4fd3-8648-289d2adfa87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting load_dotenv\n",
            "  Downloading load_dotenv-0.1.0-py3-none-any.whl (7.2 kB)\n",
            "Collecting python-dotenv (from load_dotenv)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, load_dotenv\n",
            "Successfully installed load_dotenv-0.1.0 python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# .env 파일의 경로\n",
        "env_path = '/content/drive/MyDrive/env'\n",
        "\n",
        "# .env 파일 로드\n",
        "load_dotenv(dotenv_path=env_path)\n",
        "\n",
        "# 환경 변수 가져오기\n",
        "api_key = os.getenv('API_KEY')"
      ],
      "metadata": {
        "id": "uxkxyP8fliC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwdfnSoClstP",
        "outputId": "cb7322a8-bae8-475c-d403-7bedd459c6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.10-py3-none-any.whl (990 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.0/990.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.22 (from langchain)\n",
            "  Downloading langchain_core-0.2.22-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.5/373.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.93-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.22->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.22->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.10 langchain-core-0.2.22 langchain-text-splitters-0.2.2 langsmith-0.1.93 orjson-3.10.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBmcJyYalt8H",
        "outputId": "e338db0e-04d3-4559-8613-5e8ae1379140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.10)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.22 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.22)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.93)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.22->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.22->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.9 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAJEfkMmlu8r",
        "outputId": "4c573fa1-76aa-4c2a-c479-453cbbbb8377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.7-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.6 (from pymupdf)\n",
            "  Downloading PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\n",
            "Successfully installed PyMuPDFb-1.24.6 pymupdf-1.24.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFLItaEflvum",
        "outputId": "f45e5d7f-72cf-42f2-d1c9-84c1f82e1ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.36.1-py3-none-any.whl (328 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/328.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.8/328.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.36.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "7uqJPMDVnT9w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "999295c9-693c-432f-902a-3d0a42a82656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m841.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.35.14\n",
            "    Uninstalling openai-1.35.14:\n",
            "      Successfully uninstalled openai-1.35.14\n",
            "Successfully installed openai-0.28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              },
              "id": "3032331364da4791bd85aea461815843"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75sQB8CFlw8F",
        "outputId": "68ec4e7d-aba0-4ac6-ff57-632d5fed1ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqmMfS8dlx38",
        "outputId": "a0c4bf53-22c0-4ea6-dff7-0c5ed86aee28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H5wPEQtIx7QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyMuPDFLoader, CSVLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "import openai\n",
        "\n",
        "# 상위 디렉터리 경로 설정\n",
        "base_directory = \"/content/drive/MyDrive/챗봇\"\n",
        "\n",
        "# 폴더 경로 및 카테고리 자동 설정 함수\n",
        "def get_folder_paths_with_categories(base_dir):\n",
        "    folder_paths_with_categories = {}\n",
        "    for folder_name in os.listdir(base_dir):\n",
        "        folder_path = os.path.join(base_dir, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            folder_paths_with_categories[folder_path] = folder_name\n",
        "    return folder_paths_with_categories\n",
        "\n",
        "folder_paths_with_categories = get_folder_paths_with_categories(base_directory)\n",
        "\n",
        "# 문서 로드 및 자동 분류 함수\n",
        "def load_and_classify_documents():\n",
        "    all_documents = []\n",
        "    for folder_path, category in folder_paths_with_categories.items():\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                if file_path.endswith(\".pdf\"):\n",
        "                    loader = PyMuPDFLoader(file_path)\n",
        "                elif file_path.endswith(\".csv\"):\n",
        "                    loader = CSVLoader(file_path)\n",
        "                else:\n",
        "                    continue  # 지원하지 않는 파일 형식은 건너뜀\n",
        "\n",
        "                docs = loader.load()\n",
        "\n",
        "                for i, doc in enumerate(docs):\n",
        "                    doc.metadata[\"source\"] = os.path.basename(file_path)  # 파일명을 소스로 설정\n",
        "                    doc.metadata[\"category\"] = category  # 폴더별 카테고리 설정\n",
        "                    doc.metadata[\"page\"] = i + 1  # 페이지 번호 추가\n",
        "\n",
        "                all_documents.extend(docs)\n",
        "    return all_documents\n",
        "\n",
        "# 모든 문서 로드 및 메타 데이터 추가\n",
        "all_documents = load_and_classify_documents()\n",
        "\n",
        "# 문서 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "split_documents = text_splitter.split_documents(all_documents)\n",
        "\n",
        "# 임베딩 생성\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# 벡터스토어 생성\n",
        "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
        "\n",
        "# 검색기 생성\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# 프롬프트 템플릿 설정 함수\n",
        "def get_prompt_template():\n",
        "    return \"\"\"\n",
        "        당신은 질의 응답 작업의 보조자입니다.\n",
        "        다음 검색된 컨텍스트 조각을 사용하여 질문에 답하세요.\n",
        "        답을 모르면 모른다고 하면 됩니다.\n",
        "        딱딱하게 대답하지 말고 친근한 어조로 대답하세요.\n",
        "        답변을 찾은 문서의 제목과 페이지를 알려주세요.\n",
        "        답변 문서의 카테고리도 알려주세요.\n",
        "        한국어로 대답하세요.\n",
        "\n",
        "        # Question:\n",
        "        {question}\n",
        "        # Context:\n",
        "        {context}\n",
        "\n",
        "        # Answer:\n",
        "        \"\"\"\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "openai.api_key = \"본인 키 입력\"\n",
        "\n",
        "# 체인 생성 함수\n",
        "def create_qa_chain(prompt_template):\n",
        "    def qa_chain(input_dict):\n",
        "        context_docs = retriever.get_relevant_documents(input_dict[\"query\"])\n",
        "        context_with_metadata = []\n",
        "        for doc in context_docs:\n",
        "            context_with_metadata.append(f\"출처: {doc.metadata['source']} (페이지 {doc.metadata['page']}, 카테고리 {doc.metadata['category']})\\n{doc.page_content}\\n\")\n",
        "\n",
        "        context = \"\\n\".join(context_with_metadata)\n",
        "        prompt = prompt_template.format(\n",
        "            question=input_dict[\"query\"],\n",
        "            context=context\n",
        "        )\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    return qa_chain\n",
        "\n",
        "# 사용자의 질문에 따라 해당 카테고리의 문서로 이동하여 질문에 대한 답변 생성\n",
        "def answer_question_based_on_metadata(question):\n",
        "    context_docs = retriever.get_relevant_documents(question)\n",
        "    if context_docs:\n",
        "        # 가장 관련성 높은 문서의 카테고리를 사용\n",
        "        primary_doc = context_docs[0]\n",
        "        category = primary_doc.metadata[\"category\"]\n",
        "\n",
        "        # 동일한 카테고리의 문서 필터링\n",
        "        filtered_docs = [doc for doc in context_docs if doc.metadata[\"category\"] == category]\n",
        "\n",
        "        if not filtered_docs:\n",
        "            return \"해당 카테고리에 관련된 문서를 찾을 수 없습니다.\"\n",
        "\n",
        "        context_with_metadata = []\n",
        "        for doc in filtered_docs:\n",
        "            context_with_metadata.append(f\"출처: {doc.metadata['source']} (페이지 {doc.metadata['page']}, 카테고리 {doc.metadata['category']})\\n{doc.page_content}\\n\")\n",
        "\n",
        "        context = \"\\n\".join(context_with_metadata)\n",
        "        prompt_template = get_prompt_template()\n",
        "        qa_chain = create_qa_chain(prompt_template)\n",
        "        return qa_chain({\"query\": question, \"context\": context})\n",
        "    else:\n",
        "        return \"관련된 문서를 찾을 수 없습니다.\"\n",
        "\n",
        "while True:\n",
        "    # 사용자 질문 입력\n",
        "    user_question = input(\"질문을 입력하세요 (종료하려면 '종료' 입력): \").strip()\n",
        "    if user_question.lower() == \"종료\":\n",
        "        print(\"프로그램을 종료합니다.\")\n",
        "        break\n",
        "\n",
        "    # 질문에 대한 답변 생성\n",
        "    response = answer_question_based_on_metadata(user_question)\n",
        "    print(response)\n",
        "    print('-' * 150)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDw1UP02ht-k",
        "outputId": "8196e99d-68c7-461b-8d66-88d1595c90a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문을 입력하세요 (종료하려면 '종료' 입력): 안전사고 예방법 알려줘\n",
            "안전사고를 예방하는 방법에 대해 말씀드리자면, 일단 직장 내에서 일어날 수 있는 다양한 상황에 대비하는 것이 중요해요. 여러분이 하실 수 있는 몇 가지 조치를 소개해 드릴게요:\n",
            "\n",
            "1. **상황 이해하기**: 직장 내 설비와 다양한 상황을 잘 이해하고 있어야 해요. 이를 통해 발생할 수 있는 위험을 미리 인지하고 대처법을 고민할 수 있습니다.\n",
            "\n",
            "2. **응급 상황 대비**: 구급용구가 있는 장소를 확실하게 기억해두세요. 또한, 담당 구역의 구급상자는 항상 잘 정리해 두는 것이 중요해요.\n",
            "\n",
            "3. **응급처치 연습**: 인공호흡법 등 기본적이고 응급을 요하는 조치에 대해서는 잘 연습해 두어야 합니다. 사고가 발생했을 때 당황하지 않고 바로 조치를 취할 수 있어야 하니까요.\n",
            "\n",
            "4. **화재 예방과 대처**: 화재 예방을 위해 소화기의 위치를 잘 알아두고 주변을 깨끗하게 유지하세요. 불이 났을 때는 큰 소리로 알리고, 화재 보고를 신속하게 해야 합니다. 소화기 사용법도 숙지해 두는 것이 좋습니다.\n",
            "\n",
            "이러한 조치들은 '신규입사자 가이드.pdf'에서 다루어지며, 구체적으로는 페이지 38에서 화재 예방과 관련된 내용, 페이지 49에서는 응급조치에 대한 내용을 찾아볼 수 있습니다. 문서 카테고리는 신규 입사자를 위한 가이드입니다. 도움이 되셨길 바래요!\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "질문을 입력하세요 (종료하려면 '종료' 입력): 종료\n",
            "프로그램을 종료합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import re\n",
        "import json\n",
        "\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']\n",
        "\n",
        "def process_mentors_descriptions(mentors_descriptions):\n",
        "    # Initialize the recommendations list\n",
        "    recommendations = []\n",
        "\n",
        "    # Process each mentor description\n",
        "    for description in mentors_descriptions:\n",
        "        mentor_name_match = re.search(r'\\*\\*(.*?) \\((ID: \\d+)\\)\\*\\*', description)\n",
        "        recommendation_reason_match = re.search(r'\\-\\s\\*\\*추천 이유\\*\\*:\\s(.*?)(?=\\-\\s\\*\\*점수\\*\\*)', description, re.DOTALL)\n",
        "        score_match = re.search(r'\\-\\s\\*\\*점수\\*\\*:\\s([\\d.]+)/5', description)\n",
        "        score_explanation_match = re.search(r'\\-\\s\\*\\*점수가 5점이 아닌 이유\\*\\*:\\s(.*)', description)\n",
        "\n",
        "        # Construct the recommendation entry\n",
        "        recommendation = {\n",
        "            \"mentor_name\": mentor_name_match.group(1).strip(),\n",
        "            \"ID\": int(mentor_name_match.group(2).split(\": \")[1]),\n",
        "            \"recommendation_reason\": recommendation_reason_match.group(1).strip(),\n",
        "            \"score\": float(score_match.group(1)),\n",
        "            \"score_explanation\": score_explanation_match.group(1).strip()\n",
        "        }\n",
        "\n",
        "        # Add the recommendation to the list\n",
        "        recommendations.append(recommendation)\n",
        "\n",
        "    # Construct the final JSON output\n",
        "    output = {\"recommendations\": recommendations}\n",
        "\n",
        "    # Convert to JSON format\n",
        "    json_output = json.dumps(output, ensure_ascii=False, indent=2)\n",
        "\n",
        "    return json_output\n",
        "\n",
        "# 단계 1: 문서 로드(Load Documents)\n",
        "document_files = \"/content/drive/MyDrive/실험멘티1.csv\"\n",
        "\n",
        "# 선택한 문서 로드\n",
        "loader = CSVLoader(document_files)\n",
        "docs = loader.load()\n",
        "\n",
        "# 단계 2: 문서 분할(Split Documents)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200,chunk_overlap=20)\n",
        "split_documents = text_splitter.split_documents(docs)\n",
        "\n",
        "# 단계 3: 임베딩(Embedding) 생성\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "\n",
        "# 단계 4: 벡터스토어 생성(Create Vector Store)\n",
        "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
        "\n",
        "# 단계 5: 검색기(Retriever) 생성\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# 수정된 프롬프트 템플릿(Create Modified Prompt Template)\n",
        "prompt_template = \"\"\"\n",
        "모든 답변에 대해서 친근하고 부드러운 어조로 대답해주세요.\n",
        "당신은 멘토링 추천 시스템입니다.\n",
        "주어진 데이터를 바탕으로 정확하게, 여러 사항들을 고려해서 {name} 멘티에게 추천하는 멘토 반드시 세 명을 알려주세요.\n",
        "만약 2명 이하의 사람이라면 왜 부족하게 추천 해줬는지 설명해주세요.\n",
        "멘토인 사람들만 추천해주세요. 멘토의 ID를 이름 옆에 적어주세요.\n",
        "추천 이유, 점수, 점수가 5점이 아닌 이유를 각각 설명해주세요.\n",
        "\n",
        "# 질문:\n",
        "{name}에게 추천할 멘토를 찾아주세요.\n",
        "\n",
        "# 문맥:\n",
        "멘토링 추천 시스템\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# 언어모델(LLM) 생성\n",
        "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0)\n",
        "\n",
        "# 단계 6: 체인 생성(Create Chain)\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# 사용자로부터 이름 입력\n",
        "user_name = input(\"멘티의 이름을 입력하세요: \")\n",
        "\n",
        "# 프롬프트 데이터 생성(Create Prompt Data)\n",
        "prompt_data = prompt_template.format(name=user_name)\n",
        "\n",
        "# 체인을 통해 답변을 생성합니다.\n",
        "response = qa_chain({\"query\": prompt_data})\n",
        "print(response['result'])\n",
        "\n",
        "print()\n",
        "\n",
        "ids = []\n",
        "\n",
        "for document in response['source_documents']:\n",
        "    page_content = document.page_content\n",
        "\n",
        "    lines = page_content.split('\\n')\n",
        "    id_line = next((line for line in lines if line.startswith('ID:')), None)\n",
        "\n",
        "    if id_line:\n",
        "        id_value = id_line.split(':')[-1].strip()\n",
        "        ids.append(id_value)\n",
        "\n",
        "# 각 멘토들의 설명을 리스트로 저장\n",
        "mentors_descriptions = []\n",
        "\n",
        "text = response['result']\n",
        "# \"\\n\\n\"으로 텍스트를 잘라 각 멘토의 설명을 추출\n",
        "split_text = text.split(\"\\n\\n\")\n",
        "\n",
        "# 멘토 설명\n",
        "for st in range(1,len(split_text)-1):\n",
        "    mentors_descriptions.append(split_text[st])\n",
        "\n",
        "json_output = process_mentors_descriptions(mentors_descriptions)\n",
        "\n",
        "with open('/content/drive/MyDrive/recommendations.json', 'w', encoding='utf-8') as json_file:\n",
        "    json.dump(json_output, json_file, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBCELyj8SEtq",
        "outputId": "3a3b5a64-5ca5-4e6d-e69a-6a52c35977df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "멘티의 이름을 입력하세요: 한명지\n",
            "안녕하세요! 한명지 멘티님을 위한 멘토 추천을 도와드리겠습니다. 멘티님의 관심사와 성격 유형을 고려하여 최적의 멘토를 선정해보았어요.\n",
            "\n",
            "1. **김민재 (ID: 6)**\n",
            "   - **추천 이유**: 김민재 멘토님은 노래 듣기를 좋아하시는데, 이는 한명지 멘티님의 취미와 일치합니다. 또한, 김민재 멘토님은 INFJ 성격 유형으로, 감성적이고 이타적인 성향을 가지고 있어 ESFJ인 한명지 멘티님과 잘 맞을 것으로 보입니다.\n",
            "   - **점수**: 4.5/5\n",
            "   - **점수가 5점이 아닌 이유**: 멘토링 장소가 회사 외부인 점이 조금 아쉬울 수 있습니다. 멘티님과의 물리적 거리가 멘토링의 편의성을 다소 떨어뜨릴 수 있습니다.\n",
            "\n",
            "2. **김하영 (ID: 4)**\n",
            "   - **추천 이유**: 김하영 멘토님은 멘토링 경험이 풍부하며, 회사 내부에서 멘토링을 진행하시기 때문에 접근성이 좋습니다. 또한, INTP 성격 유형으로 분석적이고 논리적인 사고를 가지고 계시며, 이는 ESFJ 성격의 한명지 멘티님에게 새로운 관점을 제공할 수 있습니다.\n",
            "   - **점수**: 4/5\n",
            "   - **점수가 5점이 아닌 이유**: 취미와 관심사가 다소 다르기 때문에 개인적인 취향에서는 공감대를 형성하는 데 한계가 있을 수 있습니다.\n",
            "\n",
            "3. **김정례 (ID: 5)**\n",
            "   - **추천 이유**: 김정례 멘토님도 회사 외부에서 멘토링을 진행하시며, INFP 성격 유형으로 따뜻하고 이해심이 많은 특성을 가지고 계십니다. 이는 한명지 멘티님의 ESFJ 성격과 잘 어울릴 수 있습니다.\n",
            "   - **점수**: 3.5/5\n",
            "   - **점수가 5점이 아닌 이유**: 멘토링 장소가 회사 외부이며, 취미와 관심사에서 큰 연관성을 찾기 어렵기 때문입니다.\n",
            "\n",
            "이 세 분 모두 멘티님과 좋은 시너지를 낼 수 있는 분들이라고 생각됩니다. 멘토링을 통해 좋은 경험과 성장을 이루시길 바랍니다!\n",
            "\n"
          ]
        }
      ]
    }
  ]
}